num_samples,duration,num_epochs,loss,val_loss,num_layers,cell_type,activation,hidden_dimension,learning_rate,gradient_clipping_value,optimizer,loss_history_filename,model_filename,reverse_sequence,notes
200775,47:24:15h,150,0.195949491072,7.784921676,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-01-29_00:37:26.csv,./trained_models/2018-01-29_00:37:26-2018-01-31_00:01:42.h5,True, all samples are shuflled on every epoch
200775,30:00:00h,100,0.2139,None,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-01_16:22:39.csv,./trained_models/2018-02-01_16:22:39-2018-02-03_00:22:15.h5,False, Added reccurence dropout of 0.2
200775,16:15:28h,50,2.00876955564,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-03_14:00:00.csv,./trained_models/2018-02-03_14:00:00-2018-02-04_06:15:29.h5,False, Input dropout of 0.5
200775,35:23:15h,110,1.47597208434,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-04_10:27:57.csv,./trained_models/2018-02-04_10:27:57-2018-02-05_21:51:13.h5,False, Input dropout of 0.5
200775,13:00:00h,50,1.844,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-07_13:55:01.csv,./trained_models/2018-02-07_13:55:01-2018-02-08_03:15:08,False, dropout: input image and before softmax of 0.5, sending last 3 images. Very good results
200775,19:22:45h,50,0.823522208953,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-08_16:58:54.csv,./trained_models/2018-02-08_16:58:54-2018-02-09_12:21:40.h5,False, Sending the previous sentence with one additional encoder, last_k =3. Overfit for 50 epochs
200775,9:34:01h,25,1.70632990266,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-09_15:30:08.csv,./trained_models/2018-02-09_15:30:08-2018-02-10_01:04:10.h5,False, Sending the previous sentence with one additional encoder, last_k =3.
200775,12:52:40h,50,1.86891705098,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-12_15:36:20.csv,./trained_models/2018-02-12_15:36:20-2018-02-13_04:29:01.h5,False,dropout: input image and before softmax of 0.5, sending last 2 images. Very good results
200775,7:10:37h,19,1.76664380121,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-14_14:33:04.csv,./trained_models/2018-02-14_14:33:04-2018-02-14_21:43:42.h5,False,dropout: input image and before softmax of 0.3, last_k=3, recurrent_dropout = 0.3
200775,11:12:32h,30,1.01023810202,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-15_10:48:00.csv,./trained_models/2018-02-15_10:48:00-2018-02-15_22:00:32.h5,False,
200775,8:18:24h,25,1.65418497207,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-22_17:31:22.csv,./trained_models/2018-02-22_17:31:22-2018-02-23_01:49:46.h5,False,
200775,7:04:44h,25,2.33397364972,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-26_15:53:55.csv,./trained_models/2018-02-26_15:53:55-2018-02-26_22:58:39.h5,False,
200775,0:11:57h,1,5.001621483123669,-1,2,gru,tanh,512,0.0001,5.0,adam,./loss_logs/2018-06-05_14:37:39.csv,./trained_models/2018-06-05_14:37:39-2018-06-05_14:49:36.h5,False,
1405425,14:23:29h,4,2.9155260776696066,-1,2,gru,tanh,512,0.0001,5.0,adam,./loss_logs/2018-06-22_05:31:47.csv,./trained_models/2018-06-22_05:31:47-2018-06-22_19:55:16.h5,False,
